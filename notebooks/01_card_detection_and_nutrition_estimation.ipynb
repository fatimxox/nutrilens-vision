{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14310302,"sourceType":"datasetVersion","datasetId":9135513}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as T\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nIMG_SIZE = 640\nCARD_WIDTH_CM = 8.5\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:42:53.520302Z","iopub.execute_input":"2025-12-27T19:42:53.520536Z","iopub.status.idle":"2025-12-27T19:43:06.023134Z","shell.execute_reply.started":"2025-12-27T19:42:53.520515Z","shell.execute_reply":"2025-12-27T19:43:06.022316Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def polygon_to_bbox(poly):\n    xs = poly[0::2]\n    ys = poly[1::2]\n\n    x_min, x_max = min(xs), max(xs)\n    y_min, y_max = min(ys), max(ys)\n\n    xc = (x_min + x_max) / 2\n    yc = (y_min + y_max) / 2\n    w  = x_max - x_min\n    h  = y_max - y_min\n\n    return torch.tensor([xc, yc, w, h], dtype=torch.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:43:06.024806Z","iopub.execute_input":"2025-12-27T19:43:06.025156Z","iopub.status.idle":"2025-12-27T19:43:06.030220Z","shell.execute_reply.started":"2025-12-27T19:43:06.025132Z","shell.execute_reply":"2025-12-27T19:43:06.029511Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CardDataset(Dataset):\n    def __init__(self, img_dir, label_dir):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n\n        self.transform = T.Compose([\n            T.Resize((IMG_SIZE, IMG_SIZE)),\n            T.ToTensor()\n        ])\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n\n        image = Image.open(\n            os.path.join(self.img_dir, img_name)\n        ).convert(\"RGB\")\n        image = self.transform(image)\n\n        label_path = os.path.join(\n            self.label_dir, img_name.replace(\".jpg\", \".txt\")\n        )\n\n        with open(label_path) as f:\n            data = list(map(float, f.readline().split()))\n\n        polygon = data[1:]          # skip class id\n        bbox = polygon_to_bbox(polygon)\n\n        return image, bbox\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:43:06.031265Z","iopub.execute_input":"2025-12-27T19:43:06.031522Z","iopub.status.idle":"2025-12-27T19:43:06.053552Z","shell.execute_reply.started":"2025-12-27T19:43:06.031501Z","shell.execute_reply":"2025-12-27T19:43:06.052880Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class CardDetector(nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = torchvision.models.resnet18(weights=\"DEFAULT\")\n        self.features = nn.Sequential(*list(backbone.children())[:-1])\n\n        self.head = nn.Sequential(\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 4),\n            nn.Sigmoid()  # لأن bbox normalized\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        return self.head(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:43:06.054504Z","iopub.execute_input":"2025-12-27T19:43:06.054802Z","iopub.status.idle":"2025-12-27T19:43:06.070278Z","shell.execute_reply.started":"2025-12-27T19:43:06.054773Z","shell.execute_reply":"2025-12-27T19:43:06.069767Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_dataset = CardDataset(\n    \"/kaggle/input/ref-object/train/images\",\n    \"/kaggle/input/ref-object/train/labels\"\n)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=8, shuffle=True\n)\n\nmodel = CardDetector().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nloss_fn = nn.MSELoss()\n\nfor epoch in range(15):\n    total_loss = 0\n    for imgs, targets in train_loader:\n        imgs = imgs.to(device)\n        targets = targets.to(device)\n\n        preds = model(imgs)\n        loss = loss_fn(preds, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"card_detector.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:43:09.576401Z","iopub.execute_input":"2025-12-27T19:43:09.576721Z","iopub.status.idle":"2025-12-27T20:40:16.226501Z","shell.execute_reply.started":"2025-12-27T19:43:09.576694Z","shell.execute_reply":"2025-12-27T20:40:16.225780Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44.7M/44.7M [00:00<00:00, 165MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss = 9.0985\nEpoch 2: Loss = 2.9007\nEpoch 3: Loss = 1.8585\nEpoch 4: Loss = 1.3596\nEpoch 5: Loss = 1.0819\nEpoch 6: Loss = 0.7576\nEpoch 7: Loss = 0.6244\nEpoch 8: Loss = 0.4897\nEpoch 9: Loss = 0.3438\nEpoch 10: Loss = 0.4102\nEpoch 11: Loss = 0.2936\nEpoch 12: Loss = 0.2393\nEpoch 13: Loss = 0.2518\nEpoch 14: Loss = 0.1964\nEpoch 15: Loss = 0.1999\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"card_detector.pth\"))\nmodel.eval()\n\nimg_path = \"/kaggle/input/ref-object/test/images/20230716_043900_jpg.rf.16522fa61f87e8c05e03da432d46f447.jpg\"\nimage = cv2.imread(img_path)\nh, w, _ = image.shape\n\nimg = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\nimg = torch.tensor(img).permute(2,0,1).float().unsqueeze(0) / 255\nimg = img.to(device)\n\nwith torch.no_grad():\n    xc, yc, bw, bh = model(img)[0]\n\nbw_px = bw.item() * w\ns = bw_px / CARD_WIDTH_CM\n\nprint(\"Pixels per CM (s):\", s)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T20:42:42.895053Z","iopub.execute_input":"2025-12-27T20:42:42.895637Z","iopub.status.idle":"2025-12-27T20:42:43.212898Z","shell.execute_reply.started":"2025-12-27T20:42:42.895607Z","shell.execute_reply":"2025-12-27T20:42:43.212263Z"}},"outputs":[{"name":"stdout","text":"Pixels per CM (s): 46.883181403664985\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Nutrition DB: density (g/cm³), calories per 100g\nFOODSEG103_DB = {\n    \"rice\":               {\"density\": 0.85, \"cal_per_100g\": 130},\n    \"potato\":             {\"density\": 0.77, \"cal_per_100g\": 77},\n    \"tomato\":             {\"density\": 0.99, \"cal_per_100g\": 18},\n    \"chicken duck\":       {\"density\": 1.03, \"cal_per_100g\": 239},\n    \"steak\":              {\"density\": 1.04, \"cal_per_100g\": 250},\n    \"broccoli\":           {\"density\": 0.34, \"cal_per_100g\": 34},\n    \"ice cream\":          {\"density\": 0.56, \"cal_per_100g\": 207},\n    \"cheese butter\":      {\"density\": 0.95, \"cal_per_100g\": 402},\n    \"bread\":              {\"density\": 0.27, \"cal_per_100g\": 265},\n    \"egg\":                {\"density\": 1.03, \"cal_per_100g\": 155},\n    # Add more classes here as needed\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T21:00:18.523926Z","iopub.execute_input":"2025-12-27T21:00:18.524248Z","iopub.status.idle":"2025-12-27T21:00:18.529350Z","shell.execute_reply.started":"2025-12-27T21:00:18.524222Z","shell.execute_reply":"2025-12-27T21:00:18.528578Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport cv2\n\n# --- UTILS ---\n\n# IoU mask to area in pixels\ndef mask_area(mask):\n    return (mask > 0).sum()\n\n# Convert pixel area to cm²\ndef area_to_cm2(area_px, s):\n    return area_px / (s * s)\n\n# Weight (g) from volume and density\ndef estimate_weight(area_cm2, density, height_cm=2.5):\n    # approximate height\n    volume_cm3 = area_cm2 * height_cm\n    return volume_cm3 * density\n\n# Calories from weight\ndef estimate_calories(weight_g, cal_per_100g):\n    return (weight_g * cal_per_100g) / 100.0\n\n# --- CARD DETECTION & SCALE (s) ---\n\ndef compute_s_from_image(image_path, card_model, device):\n    \"\"\"Detect card, compute s (pixels/cm).\"\"\"\n    img = cv2.imread(image_path)\n    h, w = img.shape[:2]\n\n    tensor = torch.tensor(cv2.resize(img,(640,640))).permute(2,0,1).float().unsqueeze(0)/255\n    tensor = tensor.to(device)\n\n    with torch.no_grad():\n        xc, yc, bw, bh = card_model(tensor)[0].cpu().numpy()\n\n    card_width_px = bw * w\n    return card_width_px / 8.5  # 8.5 cm real card width\n\n# --- SEGMENT AND ESTIMATE ---\n\ndef estimate_meal_nutrition(image, seg_model, s, class_list):\n    \"\"\"Run segmentation and compute per ingredient weight/calories.\"\"\"\n    # Run segmentation (example uses a PyTorch seg model)\n    seg_input = torch.tensor(image).permute(2,0,1).float().unsqueeze(0)/255\n    seg_input = seg_input.to(next(seg_model.parameters()).device)\n    \n    with torch.no_grad():\n        seg_output = seg_model(seg_input)[\"out\"]  # shape (1,C,H,W)\n    \n    seg_mask = torch.argmax(seg_output, dim=1)[0].cpu().numpy()\n    \n    results = {}\n    \n    for idx, cls_name in class_list.items():\n        if cls_name not in FOODSEG103_DB:\n            continue\n        \n        mask = (seg_mask == idx).astype(np.uint8)\n        if mask.sum()==0:\n            continue\n        \n        area_px = mask_area(mask)\n        area_cm2 = area_to_cm2(area_px, s)\n        \n        params = FOODSEG103_DB[cls_name]\n        density = params[\"density\"]\n        cals100 = params[\"cal_per_100g\"]\n        \n        weight_g = estimate_weight(area_cm2, density)\n        cals = estimate_calories(weight_g, cals100)\n        \n        results[cls_name] = {\n            \"area_cm2\": area_cm2,\n            \"weight_g\": weight_g,\n            \"calories\": cals\n        }\n    \n    return results\n\n# --- RUN EVERYTHING ---\n\n# 1) compute scale\nimage_file = \"/kaggle/input/ref-object/test/images/20230716_043900_jpg.rf.16522fa61f87e8c05e03da432d46f447.jpg\"\ns = compute_s_from_image(image_file, model, device)\nprint(f\"Pixels/cm (s) = {s:.2f}\")\n\n# 2) load image for segmentation\nimg = cv2.imread(image_file)\nimg_resized = cv2.resize(img,(640,640))\n\n# 3) segmentation and nutrition\nnutrition = estimate_meal_nutrition(img_resized, seg_model, s, FOODSEG103_CLASS_MAP)\n\n# 4) print results\ntotal_g = 0\ntotal_cal = 0\nfor ing, info in nutrition.items():\n    print(f\"{ing}: {info['weight_g']:.1f} g, {info['calories']:.1f} kcal\")\n    total_g += info[\"weight_g\"]\n    total_cal += info[\"calories\"]\n\nprint(\"Total weight:\", total_g, \"g\")\nprint(\"Total calories:\", total_cal, \"kcal\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}